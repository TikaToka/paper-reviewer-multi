{"references": [{"fullname_first_author": "Lisa Anne Hendricks", "paper_title": "Localizing moments in video with natural language", "publication_date": "2017-10-01", "reason": "This paper is foundational to the field of Video Moment Retrieval (VMR), introducing the core task of localizing moments in untrimmed videos based on natural language queries."}, {"fullname_first_author": "Jiyang Gao", "paper_title": "TALL: Temporal activity localization via language query", "publication_date": "2017-10-01", "reason": "This paper is highly influential as it introduced the TALL dataset and established a benchmark for VMR, driving significant progress in the field."}, {"fullname_first_author": "Ranjay Krishna", "paper_title": "Dense-captioning events in videos", "publication_date": "2017-10-01", "reason": "This paper is important because it introduced the ActivityNet Captions dataset, a large-scale dataset with dense annotations, which significantly advanced the research of VMR by providing a more comprehensive data resource."}, {"fullname_first_author": "Jie Lei", "paper_title": "Detecting moments and highlights in videos via natural language queries", "publication_date": "2021-12-01", "reason": "This paper is significant due to its introduction of the MDETR model, a transformer-based approach that improved the state-of-the-art results in VMR by integrating a transformer architecture."}, {"fullname_first_author": "Guoshun Nan", "paper_title": "Interventional video grounding with dual contrastive learning", "publication_date": "2021-10-01", "reason": "This paper presented IVG-DCL, which incorporated causality-based modeling into contrastive learning for VMR, improving performance by addressing spurious correlations between videos and queries."}]}