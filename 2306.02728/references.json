{"references": [{"fullname_first_author": "Lisa Anne Hendricks", "paper_title": "Localizing moments in video with natural language", "publication_date": "2017-10-01", "reason": "This paper is foundational for the Video Moment Retrieval (VMR) task, introducing a core problem the current paper addresses."}, {"fullname_first_author": "Jiyang Gao", "paper_title": "TALL: Temporal activity localization via language query", "publication_date": "2017-10-01", "reason": "This is a highly influential early work on VMR, establishing the benchmarks and challenges the field addresses."}, {"fullname_first_author": "Jie Lei", "paper_title": "Detecting moments and highlights in videos via natural language queries", "publication_date": "2021-12-01", "reason": "This paper proposes MDETR, a strong baseline DETR-based model for VMR that this work directly builds upon."}, {"fullname_first_author": "Guoshun Nan", "paper_title": "Interventional video grounding with dual contrastive learning", "publication_date": "2021-06-01", "reason": "This paper proposes a contrastive learning method relevant to VMR; it introduces challenges in contrastive learning that this paper seeks to resolve."}, {"fullname_first_author": "Hongxiang Li", "paper_title": "G2L: Semantically aligned and uniform video grounding via geodesic and game theory", "publication_date": "2023-07-14", "reason": "This is a state-of-the-art VMR method using contrastive learning; this paper improves upon it."}]}